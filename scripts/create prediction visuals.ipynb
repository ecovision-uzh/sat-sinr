{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0409635-6a23-4ec9-9842-8ae08939fe7b",
   "metadata": {},
   "source": [
    "### Creating maps from the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826fbf58-99ab-49bf-ba96-d8169f844b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "from dataset import SINR_DS\n",
    "from models import *\n",
    "from utils import DefaultParams\n",
    "from embedders import get_embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3723d-2458-4c11-aeb9-830eda95aa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_FOLDER = \"glc23_data/\"\n",
    "# dataset_file = pd.read_csv(Data_FOLDER + 'Pot_10_to_1000.csv', sep=\";\", header='infer', low_memory=False)\n",
    "dataset_file = pd.read_csv(\n",
    "    Data_FOLDER + \"Pot_10_to_1000_nofrance.csv\",\n",
    "    sep=\";\",\n",
    "    header=\"infer\",\n",
    "    low_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf55628-67b0-4d5b-84c3-7a3c7a48e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing all checkpoints in a folder\n",
    "CP_PATH = \"\"\n",
    "cps = os.listdir(CP_PATH)\n",
    "for cp in cps:\n",
    "    if \"lf\" in cp:\n",
    "        try:\n",
    "            print(cp)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96292ba-93f8-4ba5-ad7f-6b0b9dfe5323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code-Snippet to match GLC23 occurrence with gbif occurrence to retrieve the original species\n",
    "print(dataset_file[dataset_file[\"speciesId\"] == 265].iloc[0])\n",
    "import pygbif\n",
    "\n",
    "# Replace key with key from previously printed snippet\n",
    "pygbif.occurrences.get(key=3951621754)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae176f-82f5-46bd-a38d-acda7edc83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(name):\n",
    "    if \"sat\" in name:\n",
    "        sinr = False\n",
    "        PREDICTORS = \"loc_env_sent2\"\n",
    "    elif \"env\" in name:\n",
    "        sinr = True\n",
    "        PREDICTORS = \"loc_env\"\n",
    "    else:\n",
    "        sinr = True\n",
    "        PREDICTORS = \"loc\"\n",
    "    bioclim_path = Data_FOLDER + \"bioclim+elev/bioclim_elevation_scaled_europe.npy\"\n",
    "    dataset = SINR_DS(\n",
    "        dataset_file,\n",
    "        PREDICTORS,\n",
    "        sent_data_path=Data_FOLDER + \"SatelliteImages/\",\n",
    "        bioclim_path=bioclim_path,\n",
    "    )\n",
    "\n",
    "    default_params = DefaultParams(sinr)\n",
    "    default_params.dataset.predictors = PREDICTORS\n",
    "\n",
    "    if \"sat\" in name:\n",
    "        default_params.model = name.split(\" \")[0]\n",
    "        model = SAT_SINR(default_params, dataset, get_embedder(default_params))\n",
    "    else:\n",
    "        model = SINR(default_params, dataset)\n",
    "\n",
    "    path = CP_PATH + name\n",
    "\n",
    "    state_dict = torch.load(path)[\"state_dict\"]\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    return model.eval(), sinr, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c7aaa-ace7-466d-808a-1a2e77b580ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "RES_LON = 502\n",
    "RES_LAT = 408\n",
    "\n",
    "c = Counter(dataset_file[\"speciesId\"].to_numpy())\n",
    "\n",
    "max_lon = 34.55792\n",
    "min_lon = -10.53904\n",
    "max_lat = 71.18392\n",
    "min_lat = 34.56858"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f4dc4-9dc0-4f3b-b4bd-b0109800bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, sinr, dataset):\n",
    "    if sinr:\n",
    "        locs = []\n",
    "        model.net.to(\"cpu\")\n",
    "        for i in tqdm(range(RES_LON)):\n",
    "            # i is lon\n",
    "            # j is lat\n",
    "            for j in range(RES_LAT):\n",
    "                lon = i / RES_LON\n",
    "                lat = j / RES_LAT\n",
    "                lon = lon * (max_lon - min_lon) + min_lon\n",
    "                lat = lat * (max_lat - min_lat) + min_lat\n",
    "                locs.append(dataset.encode(lon, lat))\n",
    "        locs = torch.stack(locs)\n",
    "        preds = model(locs).sigmoid()\n",
    "    else:\n",
    "        preds = []\n",
    "        model.net.to(\"cuda\")\n",
    "        for i in tqdm(range(RES_LON)):\n",
    "            # i is lon\n",
    "            # j is lat\n",
    "            for j in range(RES_LAT):\n",
    "                lon = i / RES_LON\n",
    "                lat = j / RES_LAT\n",
    "                lon = lon * (max_lon - min_lon) + min_lon\n",
    "                lat = lat * (max_lat - min_lat) + min_lat\n",
    "                loc = dataset.encode(lon, lat)\n",
    "                pos = str(lat) + \",\" + str(lon)\n",
    "                # Requires downloading and cropping fitting Sentinel-2 images from the Ecodatacube\n",
    "                rgb_path = \"sentinel_2 2021 Europe/rgb/\" + pos + \".jpeg\"\n",
    "                nir_path = \"sentinel_2 2021 Europe/nir/\" + pos + \".jpeg\"\n",
    "                try:\n",
    "                    rgb = Image.open(rgb_path)\n",
    "                    nir = Image.open(nir_path)\n",
    "                    to_tensor = torchvision.transforms.PILToTensor()\n",
    "                    sent2 = torch.concat([to_tensor(rgb), to_tensor(nir)], dim=0) / 255\n",
    "                except:\n",
    "                    sent2 = torch.zeros(4, 128, 128)\n",
    "                if sent2.shape != torch.Size([4, 128, 128]):\n",
    "                    sent2 = torch.zeros(4, 128, 128)\n",
    "                with torch.no_grad():\n",
    "                    preds.append(\n",
    "                        model.net((loc.to(\"cuda\"), sent2.to(\"cuda\")), no_sent2=False)\n",
    "                        .detach()\n",
    "                        .to(\"cpu\")\n",
    "                    )\n",
    "        preds = torch.stack(preds).sigmoid()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5017c3-a4d4-48c0-8b3a-964da20a1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_save_res(preds, name, NOCCS=False, FRANCE_ONLY=False, STD=False):\n",
    "\n",
    "    try:\n",
    "        os.mkdir(\"./visuals/\" + name)\n",
    "    except:\n",
    "        pass\n",
    "    NUM_SAMPLES = len(to_map)\n",
    "\n",
    "    for sid in range(NUM_SAMPLES):\n",
    "\n",
    "        vmin = 0\n",
    "        if STD:\n",
    "            vmax = 0.5\n",
    "        else:\n",
    "            vmax = 1\n",
    "        occs = dataset_file.query(\"speciesId == \" + str(to_map[sid]))\n",
    "        assert len(occs) == num_samples[sid]\n",
    "        lon_occs = occs[\"lon\"].to_numpy()\n",
    "        lat_occs = occs[\"lat\"].to_numpy()\n",
    "\n",
    "        # Ocean mask can be downloaded the original SINR repo\n",
    "        mask = np.load(\n",
    "            os.path.join(Data_FOLDER + \"sinr_data/data/masks\", \"ocean_mask_hr.npy\")\n",
    "        )\n",
    "        lon_res = mask.shape[1] / 360\n",
    "        lat_res = mask.shape[0] / 180\n",
    "        north = int((90 - max_lat) * lat_res)\n",
    "        south = int((90 - min_lat) * lat_res)\n",
    "        west = int((180 + min_lon) * lon_res)\n",
    "        east = int((180 + max_lon) * lon_res)\n",
    "        mask = mask[north:south, west:east]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        if not FRANCE_ONLY:\n",
    "            ax.set_xlim([-10.53904, 34.55792])\n",
    "            ax.set_ylim([34.56858, 71.18392])\n",
    "        else:\n",
    "            ax.set_xlim([-4.807615, 8.238722])\n",
    "            ax.set_ylim([42.325170, 51.235825])\n",
    "        cmap = plt.cm.plasma\n",
    "        cmap.set_bad(color=\"none\")\n",
    "        mask_inds = np.where(mask.reshape(-1) == 1)[0]\n",
    "\n",
    "        im = preds[:, to_map[sid]]\n",
    "        print(\n",
    "            \"SpeciesId:\",\n",
    "            to_map[sid],\n",
    "            \"; Num samples:\",\n",
    "            num_samples[sid],\n",
    "            im.min().item(),\n",
    "            im.max().item(),\n",
    "        )\n",
    "        im = torch.rot90(im.view(RES_LON, RES_LAT))\n",
    "        im = torch.reshape(im, (RES_LAT * RES_LON, 1))\n",
    "        im = im[mask_inds]\n",
    "\n",
    "        op_im = np.ones(mask.shape[0] * mask.shape[1]) * np.nan\n",
    "        op_im[mask_inds] = im.detach().view(len(mask_inds)).numpy()\n",
    "        op_im = np.ma.masked_invalid(op_im)\n",
    "        op_im = op_im.reshape(RES_LAT, RES_LON)\n",
    "\n",
    "        TRESHHOLD = 0\n",
    "        if TRESHHOLD > 0:\n",
    "            # op_im[op_im > TRESHHOLD] = 1\n",
    "            op_im[op_im <= TRESHHOLD] = 0\n",
    "\n",
    "        if FRANCE_ONLY:\n",
    "            op_im = op_im[408 - 186 : 408 - 86, 64:209]\n",
    "\n",
    "        if FRANCE_ONLY:\n",
    "            im = ax.imshow(\n",
    "                op_im,\n",
    "                extent=(-4.807615, 8.238722, 42.325170, 51.235825),\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                cmap=cmap,\n",
    "            )\n",
    "        else:\n",
    "            im = ax.imshow(\n",
    "                op_im,\n",
    "                extent=(-10.53904, 34.55792, 34.56858, 71.18392),\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                cmap=cmap,\n",
    "            )\n",
    "        if not NOCCS:\n",
    "            ax.scatter(lon_occs, lat_occs, c=\"lime\", alpha=0.5, s=3)\n",
    "\n",
    "        if not name == \"only_dist\":\n",
    "            fig.colorbar(im, ax=ax)\n",
    "\n",
    "        fig.savefig(\n",
    "            \"./visuals/\"\n",
    "            + name\n",
    "            + \"/\"\n",
    "            + str(to_map[sid])\n",
    "            + (\"_noccs\" if NOCCS else \"\")\n",
    "            + (\"_france\" if FRANCE_ONLY else \"\")\n",
    "            + (\"_std\" if STD else \"\")\n",
    "        )\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119089bd-68c2-4f32-a8c6-3c2026aa16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_names = [\"\", \"\", \"\"]\n",
    "preds = []\n",
    "for name in checkpoint_names:\n",
    "    model, sinr, dataset = get_model(name)\n",
    "    preds.append(get_preds(model, sinr, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb5232-00b7-4da5-8545-5f74e06d3d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.stack(preds)\n",
    "preds_average = preds.mean(axis=0)\n",
    "preds_std = preds.std(axis=0)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e0720a-eb0d-4ab8-b848-0bf01424c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_map = [\n",
    "    265,\n",
    "    268,\n",
    "    271,\n",
    "    439,\n",
    "    751,\n",
    "    905,\n",
    "    966,\n",
    "    1122,\n",
    "    1224,\n",
    "    1303,\n",
    "    1559,\n",
    "    1957,\n",
    "    2071,\n",
    "    2854,\n",
    "    3207,\n",
    "    3384,\n",
    "    3947,\n",
    "    4062,\n",
    "    4269,\n",
    "    4501,\n",
    "    5022,\n",
    "    5113,\n",
    "    5400,\n",
    "    5793,\n",
    "    6510,\n",
    "    6612,\n",
    "    6895,\n",
    "    6922,\n",
    "    7519,\n",
    "    7580,\n",
    "    7760,\n",
    "    8023,\n",
    "    8196,\n",
    "    8267,\n",
    "    8586,\n",
    "    8791,\n",
    "    8994,\n",
    "    9170,\n",
    "    9240,\n",
    "    9315,\n",
    "    9509,\n",
    "    9753,\n",
    "    9761,\n",
    "    9807,\n",
    "    9983,\n",
    "]  # classes present in the first PA sample\n",
    "# to_map = random.sample(c.keys(), NUM_SAMPLES)\n",
    "to_map = [265]\n",
    "num_samples = [c[sid] for sid in to_map]\n",
    "\"\"\"name = \"only_dist\"\n",
    "preds_average = torch.zeros(502*408, 10000)\"\"\"\n",
    "print_and_save_res(preds_average, name, NOCCS=False, FRANCE_ONLY=False, STD=False)\n",
    "print_and_save_res(preds_average, name, NOCCS=False, FRANCE_ONLY=True, STD=False)\n",
    "print_and_save_res(preds_average, name, NOCCS=True, FRANCE_ONLY=False, STD=False)\n",
    "print_and_save_res(preds_average, name, NOCCS=True, FRANCE_ONLY=True, STD=False)\n",
    "\"\"\"print_and_save_res(preds_std, name, NOCCS=False, FRANCE_ONLY=False, STD=True)\n",
    "print_and_save_res(preds_std, name, NOCCS=False, FRANCE_ONLY=True, STD=True)\n",
    "print_and_save_res(preds_std, name, NOCCS=True, FRANCE_ONLY=False, STD=True)\n",
    "print_and_save_res(preds_std, name, NOCCS=True, FRANCE_ONLY=True, STD=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe50db-db92-4a67-8f32-57932f9c3824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glc23",
   "language": "python",
   "name": "glc23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
