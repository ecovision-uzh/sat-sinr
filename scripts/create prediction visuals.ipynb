{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0409635-6a23-4ec9-9842-8ae08939fe7b",
   "metadata": {},
   "source": [
    "### Creating maps from the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826fbf58-99ab-49bf-ba96-d8169f844b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "from dataset import SINR_DS\n",
    "from models import *\n",
    "from utils import DefaultParams\n",
    "from embedders import get_embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3723d-2458-4c11-aeb9-830eda95aa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_FOLDER = \"/data/jdolli/\"\n",
    "#dataset_file = pd.read_csv(Data_FOLDER + 'glc23_data/Pot_10_to_1000.csv', sep=\";\", header='infer', low_memory=False)\n",
    "dataset_file = pd.read_csv(Data_FOLDER + 'glc23_data/Pot_10_to_1000_nofrance.csv', sep=\";\", header='infer', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf55628-67b0-4d5b-84c3-7a3c7a48e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing all checkpoints in a folder\n",
    "CP_PATH = \"\"\n",
    "cps = os.listdir(CP_PATH)\n",
    "for cp in cps:\n",
    "    if \"lf\" in cp:\n",
    "        try:\n",
    "            print(cp)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96292ba-93f8-4ba5-ad7f-6b0b9dfe5323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code-Snippet to match GLC23 occurrence with gbif occurrence to retrieve the original species\n",
    "print(dataset_file[dataset_file[\"speciesId\"] == 265].iloc[0])\n",
    "import pygbif\n",
    "# Replace key with key from previously printed snippet\n",
    "pygbif.occurrences.get(key=3951621754)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae176f-82f5-46bd-a38d-acda7edc83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(name):\n",
    "    if \"sat\" in name:\n",
    "        sinr = False\n",
    "        PREDICTORS = \"loc_env_sent2\"\n",
    "    elif \"env\" in name:\n",
    "        sinr = True\n",
    "        PREDICTORS = \"loc_env\"\n",
    "    else:\n",
    "        sinr = True\n",
    "        PREDICTORS = \"loc\"\n",
    "    bioclim_path = Data_FOLDER + \"bioclim+elev/bioclim_elevation_scaled_europe.npy\"\n",
    "    dataset = SINR_DS(dataset_file, PREDICTORS, sent_data_path = Data_FOLDER + \"glc23_data/SatelliteImages/\", bioclim_path = bioclim_path, use_subm_val=False)\n",
    "\n",
    "    default_params = DefaultParams(sinr)\n",
    "    default_params.dataset.predictors = PREDICTORS\n",
    "\n",
    "    if \"sat\" in name:\n",
    "        default_params.model = name.split(\" \")[0]\n",
    "        model = SAT_SINR(default_params, dataset, get_embedder(default_params))\n",
    "    else:\n",
    "        model = SINR(default_params, dataset)\n",
    "\n",
    "    path = CP_PATH + name\n",
    "\n",
    "    state_dict = torch.load(path)[\"state_dict\"]\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    return model.eval(), sinr, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c7aaa-ace7-466d-808a-1a2e77b580ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "RES_LON = 502\n",
    "RES_LAT = 408\n",
    "\n",
    "c = Counter(dataset_file[\"speciesId\"].to_numpy())\n",
    "\n",
    "max_lon = 34.55792\n",
    "min_lon = -10.53904\n",
    "max_lat = 71.18392\n",
    "min_lat = 34.56858"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f4dc4-9dc0-4f3b-b4bd-b0109800bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, sinr, dataset):\n",
    "    if sinr:\n",
    "        locs = []\n",
    "        model.net.to(\"cpu\")\n",
    "        for i in tqdm(range(RES_LON)):\n",
    "            # i is lon\n",
    "            # j is lat\n",
    "            for j in range(RES_LAT):\n",
    "                lon = i/RES_LON\n",
    "                lat = j/RES_LAT\n",
    "                lon = lon * (max_lon - min_lon) + min_lon\n",
    "                lat = lat * (max_lat - min_lat) + min_lat\n",
    "                locs.append(dataset.encode(lon, lat))\n",
    "        locs = torch.stack(locs)\n",
    "        preds = model(locs).sigmoid()\n",
    "    else:\n",
    "        preds = []\n",
    "        model.net.to(\"cuda\")\n",
    "        for i in tqdm(range(RES_LON)):\n",
    "            # i is lon\n",
    "            # j is lat\n",
    "            for j in range(RES_LAT):\n",
    "                lon = i/RES_LON\n",
    "                lat = j/RES_LAT\n",
    "                lon = lon * (max_lon - min_lon) + min_lon\n",
    "                lat = lat * (max_lat - min_lat) + min_lat\n",
    "                loc = dataset.encode(lon, lat)\n",
    "                pos = str(lat) + \",\" + str(lon)\n",
    "                rgb_path = \"/data/jdolli/sentinel_2 2021 Europe/rgb/\" + pos  + \".jpeg\"\n",
    "                nir_path = \"/data/jdolli/sentinel_2 2021 Europe/nir/\" + pos  + \".jpeg\"\n",
    "                try:\n",
    "                    rgb = Image.open(rgb_path)\n",
    "                    nir = Image.open(nir_path)\n",
    "                    to_tensor = torchvision.transforms.PILToTensor()\n",
    "                    sent2 = torch.concat([to_tensor(rgb), to_tensor(nir)], dim=0)/255\n",
    "                except:\n",
    "                    sent2 = torch.zeros(4, 128, 128)\n",
    "                if sent2.shape != torch.Size([4, 128, 128]):\n",
    "                    sent2 = torch.zeros(4, 128, 128)\n",
    "                with torch.no_grad():\n",
    "                    preds.append(model.net((loc.to(\"cuda\"), sent2.to(\"cuda\")), no_sent2=False).detach().to(\"cpu\"))\n",
    "        preds = torch.stack(preds).sigmoid()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5017c3-a4d4-48c0-8b3a-964da20a1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_save_res(preds, name, NOCCS=False, FRANCE_ONLY=False, STD=False):\n",
    "\n",
    "    try:\n",
    "        os.mkdir(\"./visuals/\"+name)\n",
    "    except:\n",
    "        pass\n",
    "    NUM_SAMPLES = len(to_map)\n",
    "\n",
    "    for sid in range(NUM_SAMPLES):\n",
    "\n",
    "        vmin = 0\n",
    "        if STD:\n",
    "            vmax = 0.5\n",
    "        else:\n",
    "            vmax = 1\n",
    "        occs = dataset_file.query(\"speciesId == \" + str(to_map[sid]))\n",
    "        assert len(occs) == num_samples[sid]\n",
    "        lon_occs = occs[\"lon\"].to_numpy()\n",
    "        lat_occs = occs[\"lat\"].to_numpy()\n",
    "\n",
    "        mask = np.load(os.path.join(\"/data/jdolli/glc23_data/sinr_data/data/masks\", 'ocean_mask_hr.npy'))\n",
    "        lon_res = mask.shape[1] / 360\n",
    "        lat_res = mask.shape[0] / 180\n",
    "        north = int((90-max_lat) * lat_res)\n",
    "        south = int((90-min_lat) * lat_res)\n",
    "        west = int((180 + min_lon) * lon_res)\n",
    "        east = int((180 + max_lon) * lon_res)\n",
    "        mask = mask[north:south, west:east]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        if not FRANCE_ONLY:\n",
    "            ax.set_xlim([-10.53904, 34.55792])\n",
    "            ax.set_ylim([34.56858, 71.18392])\n",
    "        else:\n",
    "            ax.set_xlim([-4.807615, 8.238722])\n",
    "            ax.set_ylim([42.325170, 51.235825])\n",
    "        cmap = plt.cm.plasma\n",
    "        cmap.set_bad(color='none')\n",
    "        mask_inds = np.where(mask.reshape(-1) == 1)[0]\n",
    "\n",
    "        im = preds[:, to_map[sid]]\n",
    "        print(\"SpeciesId:\", to_map[sid], \"; Num samples:\", num_samples[sid], im.min().item(), im.max().item())\n",
    "        im = torch.rot90(im.view(RES_LON, RES_LAT))\n",
    "        im = torch.reshape(im, (RES_LAT * RES_LON, 1))\n",
    "        im = im[mask_inds]\n",
    "\n",
    "        op_im = np.ones(mask.shape[0] * mask.shape[1]) * np.nan\n",
    "        op_im[mask_inds] = im.detach().view(len(mask_inds)).numpy()\n",
    "        op_im = np.ma.masked_invalid(op_im)\n",
    "        op_im = op_im.reshape(RES_LAT, RES_LON)\n",
    "\n",
    "        TRESHHOLD = 0\n",
    "        if TRESHHOLD > 0:\n",
    "            #op_im[op_im > TRESHHOLD] = 1\n",
    "            op_im[op_im <= TRESHHOLD] = 0\n",
    "\n",
    "        if FRANCE_ONLY:\n",
    "            op_im = op_im[408-186:408-86, 64:209]\n",
    "\n",
    "        if FRANCE_ONLY:\n",
    "            im = ax.imshow(op_im, extent=(-4.807615, 8.238722, 42.325170, 51.235825), vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "        else:\n",
    "            im = ax.imshow(op_im, extent=(-10.53904, 34.55792, 34.56858, 71.18392), vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "        if not NOCCS:\n",
    "            ax.scatter(lon_occs, lat_occs, c=\"lime\", alpha=0.5, s=3)\n",
    "\n",
    "        if not name == \"only_dist\":\n",
    "            fig.colorbar(im, ax=ax)\n",
    "\n",
    "        fig.savefig(\"./visuals/\"+name+\"/\"+str(to_map[sid])+(\"_noccs\" if NOCCS else \"\")+(\"_france\" if FRANCE_ONLY else \"\")\n",
    "                   +(\"_std\" if STD else \"\"))\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119089bd-68c2-4f32-a8c6-3c2026aa16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_names = [\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\"\n",
    "]\n",
    "preds = []\n",
    "for name in checkpoint_names:\n",
    "    model, sinr, dataset = get_model(name)\n",
    "    preds.append(get_preds(model, sinr, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb5232-00b7-4da5-8545-5f74e06d3d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.stack(preds)\n",
    "preds_average = preds.mean(axis=0)\n",
    "preds_std = preds.std(axis=0)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e0720a-eb0d-4ab8-b848-0bf01424c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_map = [265, 268,271,439,751,905,966,1122,1224,1303,1559,1957,2071,2854,3207,3384,3947,4062,4269,4501,5022,5113,5400,5793,6510,6612,6895,6922,7519,7580,\n",
    "          7760,8023,8196,8267,8586,8791,8994,9170,9240,9315,9509,9753,9761,9807,9983] # classes present in the first PA sample\n",
    "# to_map = random.sample(c.keys(), NUM_SAMPLES)\n",
    "to_map = [265]\n",
    "num_samples = [c[sid] for sid in to_map]\n",
    "\"\"\"name = \"only_dist\"\n",
    "preds_average = torch.zeros(502*408, 10000)\"\"\"\n",
    "print_and_save_res(preds_average, name, NOCCS=False, FRANCE_ONLY=False, STD=False)\n",
    "print_and_save_res(preds_average, name, NOCCS=False, FRANCE_ONLY=True, STD=False)\n",
    "print_and_save_res(preds_average, name, NOCCS=True, FRANCE_ONLY=False, STD=False)\n",
    "print_and_save_res(preds_average, name, NOCCS=True, FRANCE_ONLY=True, STD=False)\n",
    "\"\"\"print_and_save_res(preds_std, name, NOCCS=False, FRANCE_ONLY=False, STD=True)\n",
    "print_and_save_res(preds_std, name, NOCCS=False, FRANCE_ONLY=True, STD=True)\n",
    "print_and_save_res(preds_std, name, NOCCS=True, FRANCE_ONLY=False, STD=True)\n",
    "print_and_save_res(preds_std, name, NOCCS=True, FRANCE_ONLY=True, STD=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe50db-db92-4a67-8f32-57932f9c3824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glc23",
   "language": "python",
   "name": "glc23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
