{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0409635-6a23-4ec9-9842-8ae08939fe7b",
   "metadata": {},
   "source": [
    "### Creating maps from the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "826fbf58-99ab-49bf-ba96-d8169f844b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jdolli/data/conda/envs/glc23/lib/python3.9/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/jdolli/data/conda/envs/glc23/lib/python3.9/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "sys.path.append('/home/jdolli/')\n",
    "from sentinel2_foundation_model.models import Sent2AE as Sent2VAE, View\n",
    "\n",
    "from dataset import SINR_DS\n",
    "from models import *\n",
    "from utils import DefaultParams\n",
    "from embedders import get_embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94d3723d-2458-4c11-aeb9-830eda95aa8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with open(\\'/data/jdolli/glc23_data/Presence_Absence_surveys/loc_to_spec.csv\\', \"r\") as f:\\n    val_data = json.load(f)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_file = pd.read_csv('/shares/wegner.ics.uzh/glc23_data/Pot_10_to_1000.csv', sep=\";\", header='infer', low_memory=False)\n",
    "#dataset_file = pd.read_csv('/data/jdolli/glc23_data/Pot_10_to_1000_nofrance.csv', sep=\";\", header='infer', low_memory=False)\n",
    "cps = os.listdir(\"/scratch/jdolli/sent-sinr/checkpoints\")\n",
    "\"\"\"with open('/data/jdolli/glc23_data/Presence_Absence_surveys/loc_to_spec.csv', \"r\") as f:\n",
    "    val_data = json.load(f)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cf55628-67b0-4d5b-84c3-7a3c7a48e658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/scratch/jdolli/sent-sinr/checkpoints/sinr loc val_loss\\=0.1958.ckpt\n",
      "2024-03-27 07:37:30.864244\n",
      "\n",
      "/scratch/jdolli/sent-sinr/checkpoints/sinr loc val_loss\\=0.1961-v1.ckpt\n",
      "2024-03-27 07:39:26.010990\n",
      "\n",
      "/scratch/jdolli/sent-sinr/checkpoints/sinr loc nofranceval_loss\\=0.1892.ckpt\n",
      "2024-04-01 12:54:01.567731\n",
      "\n",
      "/scratch/jdolli/sent-sinr/checkpoints/sinr loc val_loss\\=0.1961-v2.ckpt\n",
      "2024-03-27 07:40:38.674199\n",
      "\n",
      "/scratch/jdolli/sent-sinr/checkpoints/sinr loc val_loss\\=0.1962-v1.ckpt\n",
      "2024-03-26 21:57:53.993858\n",
      "\n",
      "/scratch/jdolli/sent-sinr/checkpoints/sinr loc nofranceval_loss\\=0.1877.ckpt\n",
      "2024-04-01 12:56:39.718001\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "cps = os.listdir(\"/scratch/jdolli/sent-sinr/checkpoints\")\n",
    "for cp in cps:\n",
    "    if \"sinr loc \" in cp:\n",
    "        try:\n",
    "                datetime = datetime.fromtimestamp(os.path.getmtime(\"/scratch/jdolli/sent-sinr/checkpoints/\" + cp))\n",
    "            #if float(cp[-12:-7]) > 0:\n",
    "            #if str(datetime)[8:].startswith(\"22\"):\n",
    "                print()\n",
    "                cps = cp.split(\"=\")\n",
    "                cps = cps[0] + \"\\\\=\" + cps[1]\n",
    "                print(\"/scratch/jdolli/sent-sinr/checkpoints/\" + cps)\n",
    "                print(datetime)\n",
    "        except:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f96292ba-93f8-4ba5-ad7f-6b0b9dfe5323",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#print(dataset_file[dataset_file[\"speciesId\"] == 265].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84a6d1ce-8036-4bb3-9f5b-df5ffba6d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pygbif\n",
    "#pygbif.occurrences.get(key=3307191622)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "046b8f60-e1ac-4273-86b3-ef22c12bcd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'47.19296,8.30322\\nleimbach = ds[ds[\"lon\"] < 8.5113]#4]\\nleimbach = leimbach[leimbach[\"lon\"] > 8.5067]#3]\\nleimbach = leimbach[leimbach[\"lat\"] < 47.3267]\\nleimbach = leimbach[leimbach[\"lat\"] > 47.3230]\\nleimbach\\nprint(ds[ds[\"speciesId\"] == 2333].iloc[0])'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"47.19296,8.30322\n",
    "leimbach = ds[ds[\"lon\"] < 8.5113]#4]\n",
    "leimbach = leimbach[leimbach[\"lon\"] > 8.5067]#3]\n",
    "leimbach = leimbach[leimbach[\"lat\"] < 47.3267]\n",
    "leimbach = leimbach[leimbach[\"lat\"] > 47.3230]\n",
    "leimbach\n",
    "print(ds[ds[\"speciesId\"] == 2333].iloc[0])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03eb61fa-12f3-419c-85f8-50d6a89ba3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from PIL import Image\\npid = 5338128\\nrgb_path = \"/data/jdolli/glc23_data/SatelliteImages/\" + \"rgb/\" + str(pid)[-2:] + \"/\" + str(pid)[-4:-2]+ \"/\" + str(pid) + \".jpeg\"\\nrgb = Image.open(rgb_path)\\ndisplay(rgb)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from PIL import Image\n",
    "pid = 5338128\n",
    "rgb_path = \"/data/jdolli/glc23_data/SatelliteImages/\" + \"rgb/\" + str(pid)[-2:] + \"/\" + str(pid)[-4:-2]+ \"/\" + str(pid) + \".jpeg\"\n",
    "rgb = Image.open(rgb_path)\n",
    "display(rgb)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82ae176f-82f5-46bd-a38d-acda7edc83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"sat_sinr_mf_zc ae_default val_loss=-0.0052\"\n",
    "#name = \"sinr loc_env val_loss=-0.0227\"\n",
    "#name = \"sinr loc val_loss=-0.0025\"\n",
    "def get_model(name):\n",
    "    if \"sat\" in name:\n",
    "        sinr = False\n",
    "        PREDICTORS = \"loc_env_sent2\"\n",
    "    elif \"env\" in name:\n",
    "        sinr = True\n",
    "        PREDICTORS = \"loc_env\"\n",
    "    else:\n",
    "        sinr = True\n",
    "        PREDICTORS = \"loc\"\n",
    "    \n",
    "    default_params = DefaultParams(sinr)\n",
    "    default_params.dataset.predictors = PREDICTORS\n",
    "    \n",
    "    dataset = SINR_DS(default_params, dataset_file, PREDICTORS, default_params.local.bioclim_path,\n",
    "                 default_params.local.sent_data_path, use_subm_val=False)\n",
    "\n",
    "    if \"sat\" in name:\n",
    "        default_params.model = name.split(\" \")[0]\n",
    "        model = SAT_SINR(default_params, dataset, get_embedder(default_params))\n",
    "    else:\n",
    "        model = SINR(default_params, dataset)\n",
    "\n",
    "    path = \"/scratch/jdolli/sent-sinr/checkpoints/\" + name + \".ckpt\"\n",
    "\n",
    "    state_dict = torch.load(path)[\"state_dict\"]\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    return model.eval(), sinr, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e69c7aaa-ace7-466d-808a-1a2e77b580ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "RES_LON = 502\n",
    "RES_LAT = 408\n",
    "\n",
    "c = Counter(dataset_file[\"speciesId\"].to_numpy())\n",
    "# to_map = [6372, 6805, 5782, 1192, 6325]\n",
    "\n",
    "max_lon = 34.55792\n",
    "min_lon = -10.53904\n",
    "max_lat = 71.18392\n",
    "min_lat = 34.56858"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f6f4dc4-9dc0-4f3b-b4bd-b0109800bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, sinr, dataset):\n",
    "    if sinr:\n",
    "        locs = []\n",
    "        model.net.to(\"cpu\")\n",
    "        for i in tqdm(range(RES_LON)):\n",
    "            # i is lon\n",
    "            # j is lat\n",
    "            for j in range(RES_LAT):\n",
    "                lon = i/RES_LON\n",
    "                lat = j/RES_LAT\n",
    "                lon = lon * (max_lon - min_lon) + min_lon\n",
    "                lat = lat * (max_lat - min_lat) + min_lat\n",
    "                locs.append(dataset.encode(lon, lat))\n",
    "        locs = torch.stack(locs)\n",
    "        preds = model(locs).sigmoid()\n",
    "    else:\n",
    "        preds = []\n",
    "        model.net.to(\"cuda\")\n",
    "        for i in tqdm(range(RES_LON)):\n",
    "            # i is lon\n",
    "            # j is lat\n",
    "            for j in range(RES_LAT):\n",
    "                lon = i/RES_LON\n",
    "                lat = j/RES_LAT\n",
    "                lon = lon * (max_lon - min_lon) + min_lon\n",
    "                lat = lat * (max_lat - min_lat) + min_lat\n",
    "                loc = dataset.encode(lon, lat)\n",
    "                pos = str(lat) + \",\" + str(lon)\n",
    "                rgb_path = \"/data/jdolli/sentinel_2 2021 Europe/rgb/\" + pos  + \".jpeg\"\n",
    "                nir_path = \"/data/jdolli/sentinel_2 2021 Europe/nir/\" + pos  + \".jpeg\"\n",
    "                try:\n",
    "                    rgb = Image.open(rgb_path)\n",
    "                    nir = Image.open(nir_path)\n",
    "                    to_tensor = torchvision.transforms.PILToTensor()\n",
    "                    sent2 = torch.concat([to_tensor(rgb), to_tensor(nir)], dim=0)/255\n",
    "                except:\n",
    "                    sent2 = torch.zeros(4, 128, 128)\n",
    "                if sent2.shape != torch.Size([4, 128, 128]):\n",
    "                    sent2 = torch.zeros(4, 128, 128)\n",
    "                with torch.no_grad():\n",
    "                    preds.append(model.net((loc.to(\"cuda\"), sent2.to(\"cuda\"))).detach().to(\"cpu\"))\n",
    "        preds = torch.stack(preds).sigmoid() #Put it again for everything except the sigmoid fucked one\n",
    "        #preds = torch.stack(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea5017c3-a4d4-48c0-8b3a-964da20a1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_save_res(preds, name, NOCCS=False, FRANCE_ONLY=False, VAL_DATA=False, STD=False):\n",
    "    FRANCE_SE = 42.325170, 8.238722\n",
    "    FRANCE_NW = 51.235825, -4.807615\n",
    "\n",
    "    if VAL_DATA:\n",
    "        id_to_val = defaultdict(list)\n",
    "        for idx in to_map:\n",
    "            for key in val_data:\n",
    "                if idx in val_data[key]:\n",
    "                    id_to_val[str(idx)+\"_lon\"].append(float(key.split(\"/\")[0]))\n",
    "                    id_to_val[str(idx)+\"_lat\"].append(float(key.split(\"/\")[1]))\n",
    "\n",
    "\n",
    "    try:\n",
    "        os.mkdir(\"./visuals/\"+name)\n",
    "    except:\n",
    "        pass\n",
    "    NUM_SAMPLES = len(to_map)\n",
    "    #NUM_SAMPLES = 1\n",
    "\n",
    "    for sid in range(NUM_SAMPLES):\n",
    "\n",
    "        vmin = 0\n",
    "        if STD:\n",
    "            vmax = 0.5\n",
    "        else:\n",
    "            vmax = 1\n",
    "        #vmin = 0.3\n",
    "        #vmax = 0.8\n",
    "        occs = dataset_file.query(\"speciesId == \" + str(to_map[sid]))\n",
    "        assert len(occs) == num_samples[sid]\n",
    "        lon_occs = occs[\"lon\"].to_numpy()\n",
    "        lat_occs = occs[\"lat\"].to_numpy()\n",
    "        # lon, lat = dataset._normalize_loc_to_uniform(lon, lat)\n",
    "\n",
    "        mask = np.load(os.path.join(\"/data/jdolli/glc23_data/sinr_data/data/masks\", 'ocean_mask_hr.npy'))\n",
    "        lon_res = mask.shape[1] / 360\n",
    "        lat_res = mask.shape[0] / 180\n",
    "        north = int((90-max_lat) * lat_res)\n",
    "        south = int((90-min_lat) * lat_res)\n",
    "        west = int((180 + min_lon) * lon_res)\n",
    "        east = int((180 + max_lon) * lon_res)\n",
    "        mask = mask[north:south, west:east]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        if not FRANCE_ONLY:\n",
    "            ax.set_xlim([-10.53904, 34.55792])\n",
    "            ax.set_ylim([34.56858, 71.18392])\n",
    "        else:\n",
    "            ax.set_xlim([-4.807615, 8.238722])\n",
    "            ax.set_ylim([42.325170, 51.235825])\n",
    "        cmap = plt.cm.plasma\n",
    "        cmap.set_bad(color='none')\n",
    "        mask_inds = np.where(mask.reshape(-1) == 1)[0]\n",
    "\n",
    "        im = preds[:, to_map[sid]]\n",
    "        print(\"SpeciesId:\", to_map[sid], \"; Num samples:\", num_samples[sid], im.min().item(), im.max().item())\n",
    "        im = torch.rot90(im.view(RES_LON, RES_LAT))\n",
    "        im = torch.reshape(im, (RES_LAT * RES_LON, 1))\n",
    "        im = im[mask_inds]\n",
    "\n",
    "        op_im = np.ones(mask.shape[0] * mask.shape[1]) * np.nan\n",
    "        op_im[mask_inds] = im.detach().view(len(mask_inds)).numpy()\n",
    "        op_im = np.ma.masked_invalid(op_im)\n",
    "        op_im = op_im.reshape(RES_LAT, RES_LON)\n",
    "\n",
    "        TRESHHOLD = 0\n",
    "        if TRESHHOLD > 0:\n",
    "            #op_im[op_im > TRESHHOLD] = 1\n",
    "            op_im[op_im <= TRESHHOLD] = 0\n",
    "\n",
    "        if FRANCE_ONLY:\n",
    "            op_im = op_im[408-186:408-86, 64:209]\n",
    "\n",
    "        if FRANCE_ONLY:\n",
    "            im = ax.imshow(op_im, extent=(-4.807615, 8.238722, 42.325170, 51.235825), vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "        else:\n",
    "            im = ax.imshow(op_im, extent=(-10.53904, 34.55792, 34.56858, 71.18392), vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "        if not NOCCS:\n",
    "            ax.scatter(lon_occs, lat_occs, c=\"lime\", alpha=0.5, s=3)\n",
    "        if VAL_DATA:\n",
    "            ax.scatter(id_to_val[str(to_map[sid])+\"_lon\"], id_to_val[str(to_map[sid])+\"_lat\"], c=\"red\", alpha=1, s=5)\n",
    "\n",
    "        if not name == \"only_dist\":\n",
    "            fig.colorbar(im, ax=ax)\n",
    "\n",
    "        fig.savefig(\"./visuals/\"+name+\"/\"+str(to_map[sid])+(\"_noccs\" if NOCCS else \"\")+(\"_france\" if FRANCE_ONLY else \"\")\n",
    "                   +(\"_std\" if STD else \"\"))\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c5705a0-bd3b-486e-b7f1-8c99f9ad09e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119089bd-68c2-4f32-a8c6-3c2026aa16db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 502/502 [01:12<00:00,  6.94it/s]\n",
      "100%|██████████| 502/502 [01:10<00:00,  7.17it/s]\n"
     ]
    }
   ],
   "source": [
    "sat_sinr_lf = [\n",
    "\"sat_sinr_lf cnn_default val_loss=0.2126\",\n",
    "\"sat_sinr_lf cnn_default val_loss=0.2084\",\n",
    "\"sat_sinr_lf cnn_default val_loss=0.2088\",\n",
    "\"sat_sinr_lf cnn_default val_loss=0.2088-v1\"\n",
    "]\n",
    "sinr_loc_env = [\n",
    "\"sinr loc_env val_loss=0.1817\",\n",
    "\"sinr loc_env val_loss=0.1813\",\n",
    "\"sinr loc_env val_loss=0.1811\",\n",
    "\"sinr loc_env val_loss=0.1808\"\n",
    "]\n",
    "for name in sinr_loc_env:\n",
    "    model, sinr, dataset = get_model(name)\n",
    "    preds.append(get_preds(model, sinr, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a14d667-4e0e-4140-a10d-333f6a4e2b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_sinr_loc = torch.stack(preds)\n",
    "preds_sinr_loc.detach().cpu()\n",
    "preds_average = preds_sinr_loc.mean(axis=0)\n",
    "preds_std = preds_sinr_loc.std(axis=0)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e0720a-eb0d-4ab8-b848-0bf01424c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_map = [265, 268,271,439,751,905,966,1122,1224,1303,1559,1957,2071,2854,3207,3384,3947,4062,4269,4501,5022,5113,5400,5793,6510,6612,6895,6922,7519,7580,\n",
    "          7760,8023,8196,8267,8586,8791,8994,9170,9240,9315,9509,9753,9761,9807,9983] # classes present in the first PA sample\n",
    "# to_map = random.sample(c.keys(), NUM_SAMPLES)\n",
    "to_map = [265]\n",
    "num_samples = [c[sid] for sid in to_map]\n",
    "\"\"\"name = \"only_dist\"\n",
    "preds_average = torch.zeros(502*408, 10000)\"\"\"\n",
    "print_and_save_res(preds_average, name, NOCCS=False, FRANCE_ONLY=False, VAL_DATA=False, STD=False)\n",
    "print_and_save_res(preds_average, name, NOCCS=False, FRANCE_ONLY=True, VAL_DATA=False, STD=False)\n",
    "#print_and_save_res(preds_average, name, NOCCS=True, FRANCE_ONLY=False, VAL_DATA=False, STD=False)\n",
    "#print_and_save_res(preds_average, name, NOCCS=True, FRANCE_ONLY=True, VAL_DATA=False, STD=False)\n",
    "#print_and_save_res(preds_std, name, NOCCS=False, FRANCE_ONLY=False, VAL_DATA=False, STD=True)\n",
    "#print_and_save_res(preds_std, name, NOCCS=False, FRANCE_ONLY=True, VAL_DATA=False, STD=True)\n",
    "print_and_save_res(preds_std, name, NOCCS=True, FRANCE_ONLY=False, VAL_DATA=False, STD=True)\n",
    "#print_and_save_res(preds_std, name, NOCCS=True, FRANCE_ONLY=True, VAL_DATA=False, STD=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe50db-db92-4a67-8f32-57932f9c3824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glc23",
   "language": "python",
   "name": "glc23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
