{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0409635-6a23-4ec9-9842-8ae08939fe7b",
   "metadata": {},
   "source": [
    "### Creating maps from the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826fbf58-99ab-49bf-ba96-d8169f844b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "sys.path.append('/home/jdolli/')\n",
    "from sentinel2_foundation_model.models import Sent2AE as Sent2VAE, View\n",
    "\n",
    "from dataset import SINR_DS\n",
    "from models import *\n",
    "from utils import DefaultParams\n",
    "from embedders import get_embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3723d-2458-4c11-aeb9-830eda95aa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_file = pd.read_csv('/data/jdolli/glc23_data/Pot_10_to_1000.csv', sep=\";\", header='infer', low_memory=False)\n",
    "dataset_file = pd.read_csv('/data/jdolli/glc23_data/Pot_10_to_1000_nofrance.csv', sep=\";\", header='infer', low_memory=False)\n",
    "cps = os.listdir(\"/scratch/jdolli/sent-sinr/checkpoints\")\n",
    "with open('/data/jdolli/glc23_data/Presence_Absence_surveys/loc_to_spec.csv', \"r\") as f:\n",
    "    val_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf55628-67b0-4d5b-84c3-7a3c7a48e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "cps = os.listdir(\"/scratch/jdolli/sent-sinr/checkpoints\")\n",
    "for cp in cps:\n",
    "    if \"plus\" in cp:\n",
    "        try:\n",
    "            #if float(cp[-12:-7]) > 0:\n",
    "                print(cp)\n",
    "        except:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96292ba-93f8-4ba5-ad7f-6b0b9dfe5323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dataset_file[dataset_file[\"speciesId\"] == 265].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a6d1ce-8036-4bb3-9f5b-df5ffba6d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pygbif\n",
    "#pygbif.occurrences.get(key=3951621754)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae176f-82f5-46bd-a38d-acda7edc83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"sat_sinr_mf_zc ae_default val_loss=-0.0052\"\n",
    "#name = \"sinr loc_env val_loss=-0.0227\"\n",
    "#name = \"sinr loc val_loss=-0.0025\"\n",
    "def get_model(name):\n",
    "    if \"sat\" in name:\n",
    "        sinr = False\n",
    "        PREDICTORS = \"loc_env_sent2\"\n",
    "    elif \"env\" in name:\n",
    "        sinr = True\n",
    "        PREDICTORS = \"loc_env\"\n",
    "    else:\n",
    "        sinr = True\n",
    "        PREDICTORS = \"loc\"\n",
    "    if PREDICTORS.endswith(\"LR\"):\n",
    "        bioclim_path = \"/data/jdolli/glc23_data/sinr_data/data/env/bioclim_elevation_scaled_europe.npy\"\n",
    "    else:\n",
    "        bioclim_path = \"/data/jdolli/bioclim+elev/bioclim_elevation_scaled_europe.npy\"\n",
    "    dataset = SINR_DS(dataset_file, PREDICTORS, sent_data_path = \"/data/jdolli/glc23_data/SatelliteImages/\", bioclim_path = bioclim_path, use_subm_val=False)\n",
    "\n",
    "    default_params = DefaultParams(sinr)\n",
    "    default_params.dataset.predictors = PREDICTORS\n",
    "\n",
    "    if \"sat\" in name:\n",
    "        default_params.model = name.split(\" \")[0]\n",
    "        model = SAT_SINR(default_params, dataset, get_embedder(default_params))\n",
    "    else:\n",
    "        model = SINR(default_params, dataset)\n",
    "\n",
    "    path = \"/scratch/jdolli/sent-sinr/checkpoints/\" + name + \".ckpt\"\n",
    "\n",
    "    state_dict = torch.load(path)[\"state_dict\"]\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    return model.eval(), sinr, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c7aaa-ace7-466d-808a-1a2e77b580ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "RES_LON = 502\n",
    "RES_LAT = 408\n",
    "\n",
    "c = Counter(dataset_file[\"speciesId\"].to_numpy())\n",
    "# to_map = [6372, 6805, 5782, 1192, 6325]\n",
    "\n",
    "max_lon = 34.55792\n",
    "min_lon = -10.53904\n",
    "max_lat = 71.18392\n",
    "min_lat = 34.56858"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f4dc4-9dc0-4f3b-b4bd-b0109800bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, sinr, dataset):\n",
    "    if sinr:\n",
    "        locs = []\n",
    "        model.net.to(\"cpu\")\n",
    "        for i in tqdm(range(RES_LON)):\n",
    "            # i is lon\n",
    "            # j is lat\n",
    "            for j in range(RES_LAT):\n",
    "                lon = i/RES_LON\n",
    "                lat = j/RES_LAT\n",
    "                lon = lon * (max_lon - min_lon) + min_lon\n",
    "                lat = lat * (max_lat - min_lat) + min_lat\n",
    "                locs.append(dataset.encode(lon, lat))\n",
    "        locs = torch.stack(locs)\n",
    "        preds = model(locs).sigmoid()\n",
    "    else:\n",
    "        preds = []\n",
    "        model.net.to(\"cuda\")\n",
    "        for i in tqdm(range(RES_LON)):\n",
    "            # i is lon\n",
    "            # j is lat\n",
    "            for j in range(RES_LAT):\n",
    "                lon = i/RES_LON\n",
    "                lat = j/RES_LAT\n",
    "                lon = lon * (max_lon - min_lon) + min_lon\n",
    "                lat = lat * (max_lat - min_lat) + min_lat\n",
    "                loc = dataset.encode(lon, lat)\n",
    "                pos = str(lat) + \",\" + str(lon)\n",
    "                rgb_path = \"/data/jdolli/sentinel_2 2021 Europe/rgb/\" + pos  + \".jpeg\"\n",
    "                nir_path = \"/data/jdolli/sentinel_2 2021 Europe/nir/\" + pos  + \".jpeg\"\n",
    "                try:\n",
    "                    rgb = Image.open(rgb_path)\n",
    "                    nir = Image.open(nir_path)\n",
    "                    to_tensor = torchvision.transforms.PILToTensor()\n",
    "                    sent2 = torch.concat([to_tensor(rgb), to_tensor(nir)], dim=0)/255\n",
    "                except:\n",
    "                    sent2 = torch.zeros(4, 128, 128)\n",
    "                if sent2.shape != torch.Size([4, 128, 128]):\n",
    "                    sent2 = torch.zeros(4, 128, 128)\n",
    "                with torch.no_grad():\n",
    "                    preds.append(model.net((loc.to(\"cuda\"), sent2.to(\"cuda\")), no_sent2=False).detach().to(\"cpu\"))\n",
    "        preds = torch.stack(preds).sigmoid() #Put it again for everything except the sigmoid fucked one\n",
    "        #preds = torch.stack(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5017c3-a4d4-48c0-8b3a-964da20a1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_save_res(preds, name, NOCCS=False, FRANCE_ONLY=False, VAL_DATA=False, STD=False):\n",
    "    FRANCE_SE = 42.325170, 8.238722\n",
    "    FRANCE_NW = 51.235825, -4.807615\n",
    "\n",
    "    if VAL_DATA:\n",
    "        id_to_val = defaultdict(list)\n",
    "        for idx in to_map:\n",
    "            for key in val_data:\n",
    "                if idx in val_data[key]:\n",
    "                    id_to_val[str(idx)+\"_lon\"].append(float(key.split(\"/\")[0]))\n",
    "                    id_to_val[str(idx)+\"_lat\"].append(float(key.split(\"/\")[1]))\n",
    "\n",
    "\n",
    "    try:\n",
    "        os.mkdir(\"./visuals/\"+name)\n",
    "    except:\n",
    "        pass\n",
    "    NUM_SAMPLES = len(to_map)\n",
    "    #NUM_SAMPLES = 1\n",
    "\n",
    "    for sid in range(NUM_SAMPLES):\n",
    "\n",
    "        vmin = 0\n",
    "        if STD:\n",
    "            vmax = 0.5\n",
    "        else:\n",
    "            vmax = 1\n",
    "        #vmin = 0.3\n",
    "        #vmax = 0.8\n",
    "        occs = dataset_file.query(\"speciesId == \" + str(to_map[sid]))\n",
    "        assert len(occs) == num_samples[sid]\n",
    "        lon_occs = occs[\"lon\"].to_numpy()\n",
    "        lat_occs = occs[\"lat\"].to_numpy()\n",
    "        # lon, lat = dataset._normalize_loc_to_uniform(lon, lat)\n",
    "\n",
    "        mask = np.load(os.path.join(\"/data/jdolli/glc23_data/sinr_data/data/masks\", 'ocean_mask_hr.npy'))\n",
    "        lon_res = mask.shape[1] / 360\n",
    "        lat_res = mask.shape[0] / 180\n",
    "        north = int((90-max_lat) * lat_res)\n",
    "        south = int((90-min_lat) * lat_res)\n",
    "        west = int((180 + min_lon) * lon_res)\n",
    "        east = int((180 + max_lon) * lon_res)\n",
    "        mask = mask[north:south, west:east]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        if not FRANCE_ONLY:\n",
    "            ax.set_xlim([-10.53904, 34.55792])\n",
    "            ax.set_ylim([34.56858, 71.18392])\n",
    "        else:\n",
    "            ax.set_xlim([-4.807615, 8.238722])\n",
    "            ax.set_ylim([42.325170, 51.235825])\n",
    "        cmap = plt.cm.plasma\n",
    "        cmap.set_bad(color='none')\n",
    "        mask_inds = np.where(mask.reshape(-1) == 1)[0]\n",
    "\n",
    "        im = preds[:, to_map[sid]]\n",
    "        print(\"SpeciesId:\", to_map[sid], \"; Num samples:\", num_samples[sid], im.min().item(), im.max().item())\n",
    "        im = torch.rot90(im.view(RES_LON, RES_LAT))\n",
    "        im = torch.reshape(im, (RES_LAT * RES_LON, 1))\n",
    "        im = im[mask_inds]\n",
    "\n",
    "        op_im = np.ones(mask.shape[0] * mask.shape[1]) * np.nan\n",
    "        op_im[mask_inds] = im.detach().view(len(mask_inds)).numpy()\n",
    "        op_im = np.ma.masked_invalid(op_im)\n",
    "        op_im = op_im.reshape(RES_LAT, RES_LON)\n",
    "\n",
    "        TRESHHOLD = 0\n",
    "        if TRESHHOLD > 0:\n",
    "            #op_im[op_im > TRESHHOLD] = 1\n",
    "            op_im[op_im <= TRESHHOLD] = 0\n",
    "\n",
    "        if FRANCE_ONLY:\n",
    "            op_im = op_im[408-186:408-86, 64:209]\n",
    "\n",
    "        if FRANCE_ONLY:\n",
    "            im = ax.imshow(op_im, extent=(-4.807615, 8.238722, 42.325170, 51.235825), vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "        else:\n",
    "            im = ax.imshow(op_im, extent=(-10.53904, 34.55792, 34.56858, 71.18392), vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "        if not NOCCS:\n",
    "            ax.scatter(lon_occs, lat_occs, c=\"lime\", alpha=0.5, s=3)\n",
    "        if VAL_DATA:\n",
    "            ax.scatter(id_to_val[str(to_map[sid])+\"_lon\"], id_to_val[str(to_map[sid])+\"_lat\"], c=\"red\", alpha=1, s=5)\n",
    "\n",
    "        if not name == \"only_dist\":\n",
    "            fig.colorbar(im, ax=ax)\n",
    "\n",
    "        fig.savefig(\"./visuals/\"+name+\"/\"+str(to_map[sid])+(\"_noccs\" if NOCCS else \"\")+(\"_france\" if FRANCE_ONLY else \"\")\n",
    "                   +(\"_std\" if STD else \"\"))\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119089bd-68c2-4f32-a8c6-3c2026aa16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_sinr_lf = [\n",
    "    \"sat_sinr_lf ae_default val_loss=0.0342\",\n",
    "    \"sat_sinr_lf ae_default val_loss=0.0358\",\n",
    "    \"sat_sinr_lf ae_default val_loss=0.0353\",\n",
    "    \"sat_sinr_lf ae_default val_loss=0.0345\",\n",
    "    \"sat_sinr_lf ae_default val_loss=0.0372\"\n",
    "]\n",
    "sat_sinr_mf_zc = [\n",
    "    \"sat_sinr_mf_zc ae_default val_loss=-0.0047\",\n",
    "    \"sat_sinr_mf_zc ae_default val_loss=-0.0046-v1\",\n",
    "    \"sat_sinr_mf_zc ae_default val_loss=-0.0071-v1\",\n",
    "    \"sat_sinr_mf_zc ae_default val_loss=-0.0062\",\n",
    "    \"sat_sinr_mf_zc ae_default val_loss=-0.0052\",\n",
    "]\n",
    "sinr_loc = [\n",
    "    \"sinr loc val_loss=0.0011\",\n",
    "    \"sinr loc val_loss=0.0006\",\n",
    "    \"sinr loc val_loss=-0.0040\",\n",
    "    \"sinr loc val_loss=0.0000\",\n",
    "    \"sinr loc val_loss=-0.0028\"\n",
    "]\n",
    "sinr_loc_env = [\n",
    "    \"sinr loc_env val_loss=-0.0267\",\n",
    "    \"sinr loc_env val_loss=-0.0240\",\n",
    "    \"sinr loc_env val_loss=-0.0238\",\n",
    "    \"sinr loc_env val_loss=-0.0222\",\n",
    "    \"sinr loc_env val_loss=-0.0233-v1\"\n",
    "]\n",
    "SIGM_FCK = [\n",
    "\"sat_sinr_lf ae_default SIGMOID FCKEDval_loss=0.0263\",\n",
    "\"sat_sinr_lf ae_default SIGMOID FCKEDval_loss=0.0195\",\n",
    "\"sat_sinr_lf ae_default SIGMOID FCKEDval_loss=0.0259\"\n",
    "]\n",
    "lf_plus=[\n",
    "\"sat_sinr_lf ae_default plusval_loss=0.0077\",\n",
    "\"sat_sinr_lf ae_default plusval_loss=0.0068\",\n",
    "\"sat_sinr_lf ae_default plusval_loss=0.0083\",\n",
    "\"sat_sinr_lf ae_default plusval_loss=0.0064\"\n",
    "]\n",
    "preds = []\n",
    "for name in lf_plus[:3]:\n",
    "    model, sinr, dataset = get_model(name)\n",
    "    preds.append(get_preds(model, sinr, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a14d667-4e0e-4140-a10d-333f6a4e2b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_sinr_loc = torch.stack(preds)\n",
    "preds_average = preds_sinr_loc.mean(axis=0)\n",
    "preds_std = preds_sinr_loc.std(axis=0)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b9c2f9-d9af-4e80-b8fe-ba1ac2f2e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_sinr_lf_plus = torch.stack(preds)\n",
    "preds_average = preds_sinr_lf_plus.mean(axis=0)\n",
    "preds_std = preds_sinr_lf_plus.std(axis=0)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c486ebd-9afb-4367-8650-06c1689ac3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_sinr_fuck = torch.stack(preds)\n",
    "preds_average = preds_sinr_fuck.mean(axis=0)\n",
    "preds_std = preds_sinr_fuck.std(axis=0)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e00ac6-3fa7-4473-85d6-21db1798467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_sinr_loc_env = torch.stack(preds)\n",
    "preds_average = preds_sinr_loc_env.mean(axis=0)\n",
    "preds_std = preds_sinr_loc_env.std(axis=0)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d42febd-09af-4a50-85c4-e27b767ed012",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_lf = torch.stack(preds)\n",
    "preds_average = preds_lf.mean(axis=0)\n",
    "preds_std = preds_lf.std(axis=0)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb5232-00b7-4da5-8545-5f74e06d3d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_mf_zc = torch.stack(preds)\n",
    "preds_average = preds_mf_zc.mean(axis=0)\n",
    "preds_std = preds_mf_zc.std(axis=0)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e0720a-eb0d-4ab8-b848-0bf01424c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_map = [265, 268,271,439,751,905,966,1122,1224,1303,1559,1957,2071,2854,3207,3384,3947,4062,4269,4501,5022,5113,5400,5793,6510,6612,6895,6922,7519,7580,\n",
    "          7760,8023,8196,8267,8586,8791,8994,9170,9240,9315,9509,9753,9761,9807,9983] # classes present in the first PA sample\n",
    "# to_map = random.sample(c.keys(), NUM_SAMPLES)\n",
    "to_map = [265]\n",
    "num_samples = [c[sid] for sid in to_map]\n",
    "\"\"\"name = \"only_dist\"\n",
    "preds_average = torch.zeros(502*408, 10000)\"\"\"\n",
    "print_and_save_res(preds_average, name, NOCCS=False, FRANCE_ONLY=False, VAL_DATA=False, STD=False)\n",
    "print_and_save_res(preds_average, name, NOCCS=False, FRANCE_ONLY=True, VAL_DATA=False, STD=False)\n",
    "print_and_save_res(preds_average, name, NOCCS=True, FRANCE_ONLY=False, VAL_DATA=False, STD=False)\n",
    "print_and_save_res(preds_average, name, NOCCS=True, FRANCE_ONLY=True, VAL_DATA=False, STD=False)\n",
    "\"\"\"print_and_save_res(preds_std, name, NOCCS=False, FRANCE_ONLY=False, VAL_DATA=False, STD=True)\n",
    "print_and_save_res(preds_std, name, NOCCS=False, FRANCE_ONLY=True, VAL_DATA=False, STD=True)\n",
    "print_and_save_res(preds_std, name, NOCCS=True, FRANCE_ONLY=False, VAL_DATA=False, STD=True)\n",
    "print_and_save_res(preds_std, name, NOCCS=True, FRANCE_ONLY=True, VAL_DATA=False, STD=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe50db-db92-4a67-8f32-57932f9c3824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glc23",
   "language": "python",
   "name": "glc23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
